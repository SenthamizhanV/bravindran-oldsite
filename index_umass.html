<html>
<head>
<title>Ravindran's Home</title>
</head>
<body bgcolor="f0eed0" text="000000" link="0000cc" vlink="000077" alink="56bb55">
<center>
<FONT size="+3">Ravi's Home</FONT><!-- <img src="pics/title.gif" border=0> -->
<hr width=25% size=3>
</center>
<p>
<img width=19% align="right" src="pics/ravi.jpg" alt="snapshot">
I am an assistant professor at the Department of <a
href="http://www.cs.iitm.ernet.in">Computer Science and
Engineering</a> at the <a href="http://www.iitm.ac.in">Indian
Institute of Technology, Madras</a>. I recently
completed  my Ph.D. at the <a href="http://www.cs.umass.edu">Computer
Science</a> department of <a href="http://www.umass.edu">University of
Massachusetts</a>,<a href="http://www.amherstcommon.com">
Amherst</a>. I worked with <a href="/People/barto/barto.html">Prof. Andrew
G. Barto</a> in the <A href="http://www-all.cs.umass.edu/">Autonomous
Learning Laboratory</a>, on <a href="/rlr">Reinforcement Learning</a>.
My current research interests include finding better representational
idioms, exploiting structure and symmetry of a problem
and making connections between RL and classical AI.<p>

I did my schooling in <a href="http://learning.indiatimes.com/school/pages/homepages/chennai/chnschqu/chnsbaihss1.htm">St. Bede's A.I.H.S.S</a>,
<a href="http://www.madras.com">Madras</a>.
Graduated with a Bachelor's degree in Electronics and Communications Engineering
from <a href="http://www.tce.edu">Thiagarajar College of Engineering</a>,
<a href="http://www.madurai.com">Madurai</a> in
1993. Completed my Master's in
<a href="http://www.csa.iisc.ernet.in">Computer Science</a>, at the
<a href="http://www.iisc.ernet.in">Indian Institute
of Science</a>,
<a href="http://ece.iisc.ernet.in/bu.edu/karnataka/cities/bangalore/">Bangalore</a>,
India,
under <a href="http://guppy.mpe.nus.edu.sg/~mpessk/">Prof. S. Sathiya Keerthi</a>
in the <a href="http://isl.csa.iisc.ernet.in/">Intelligent Systems
Lab</a>.
<p>
<hr>
<h3>Publications</h3>
<ul>
<p><li>Ravindran, B. (2004) &quot;<a href="thesis.pdf">An Algebraic
Approach to Abstraction in  Reinforcement Learning</a>&quot;. Doctoral
Dissertation, Department of Computer Science, University of
Massachusetts, Amherst MA.
<p><li> Ravindran, B. and Barto, A. G. (2003) &quot;<a
href="ICML03.pdf">Relativized Options: Choosing the Right
Transformation</a>&quot;. In the <i>Proceedings of the <a href
="http://www.hpl.hp.com/conferences/icml03/">Twentieth
International Conference on Machine Learning</a>(ICML 2003)</i>, pp.
608-615. AAAI Press.

<p><li> Ravindran, B. and Barto, A. G. (2003) &quot;<a
href="IJCAI03.pdf">SMDP Homomorphisms: An Algebraic Approach to
Abstraction in Semi Markov Decision Processes</a>&quot;. To appear in the
<i>Proceedings of the <a href="http://www.ijcai-03.org/">Eighteenth International Joint Conference on
Artificial Intelligence</a> (IJCAI 03)</i>, pp. 1011-1016. AAAI Press.

<p><li> Ravindran, B. and Barto, A. G. (2003) &quot;<a
href="WALS03.pdf">An Algebraic Approach to
Abstraction in Reinforcement Learning</a>&quot;. In the
<i>Proceedings of the <a href="http://www.eng.yale.edu/wals03/">Twelfth Yale Workshop on Adaptive and Learning
Systems</a></i>, pp. 109-114. Yale University.

<p><li> Ravindran, B. and Barto, A. G. (2002) &quot;<a
href="SARA02.pdf">Model Minimization in Hierarchical Reinforcement
Learning</a>&quot;. In the
<i>Proceedings of the <a
href="http://www.cs.ualberta.ca/~holte/SARA2002/">Fifth Symposium on Abstraction, Reformulation and
Approximation</a> (SARA 2002)</i>, pp.196-211, <a
href="http://www.springer.de/comp/lncs/index.html">LNCS</a>, Springer
Verlag. (Slides from presentation: <a href="sara02-presented.htm">IE</a>, <a
href="sara02-presented-univ.htm">Netscape</a>, <a
href="sara02-presented.ppt">PPT</a>)

<p> <li> Ravindran, B.
and Barto, A. G. (2001)  &quot;<A
href="TR01-43.ps">Symmetries and Model Minimization of Markov
Decision Processes</a>&quot;. Computer Science Technical Report 01-43,
University of Massachusetts, Amherst, MA.

<p><li> <A HREF="http://www.cs.umass.edu/~rich">Sutton, R. S.</a>, <A
HREF="http://www.eecs.umich.edu/~baveja">Singh, S.</a>,   <A
HREF="http://www.cs.mcgill.ca/~dprecup">Precup, D.</a> and  <A
HREF="http://www.cs.umass.edu/~ravi">Ravindran, B.</a> (1999) &quot;<A
HREF="http://www-all.cs.umass.edu/pubs/1999/sutton_spr_NIPS99.ps">Improved
Switching among Temporally Abstract Actions</a>&quot;. In
<i>Advances in Neural Information Processing Systems 11 (Proceedings of
<A
HREF="http://www.cs.cmu.edu/Groups/NIPS/NIPS98/nips98.html">NIPS'98</a>)</i>,
pp.1066-1072. MIT Press.

<p> <li> <a href="http://www-all.cs.umass.edu/~amy">McGovern, Amy </a>,
<a href="http://www.cs.mcgill.ca/~dprecup">Precup, Doina</a>,
<a href="http://www-all.cs.umass.edu/~ravi">Ravindran, B.</a>,
<a href="http://www.eecs.umich.edu/~baveja">Singh, Satinder </a> and
<A HREF="http://www.cs.umass.edu/~rich">Sutton, Richard S.</a>
(1998) &quot;<a
href="http://www-all.cs.umass.edu/pubs/1998/mcgovern_prs_YALE98.ps">
Hierarchical Optimal Control of MDPs</a>&quot;, <i>Proceedings of the
Tenth Yale Workshop on Adaptive
and Learning Systems</i>, pp.186-191.

<p><li> Ravindran, B. (1996) &quot;<a href="ms_thesis.ps.gz">Solution of Delayed Reinforcement
Learning Problems having Continuous Action Spaces</a>&quot;, <i>
Master's Thesis</i>, Department of Computer Science and Automation,
Indian Institute of Science, Bangalore, India.

<p><li> Keerthi, S. S. and Ravindran, B. (1996) &quot;<a
href="hbook.ps.gz">C3: Reinforcement Learning</a>&quot;.
In <i><a href="http://www.iop.org/Books/CIL/HNC/">Handbook Of Neural
Computation</a></i>, E. Fiesler and R. Beale,
Editors, Oxford University Press, U. K.

<p><li> Keerthi, S. S. and Ravindran, B. (1994) &quot;<a
href="ftp://archive.cis.ohio-state.edu/pub/neuroprose/keerthi.rl-survey.ps.Z">A
Tutorial Survey Of Reinforcement Learning</a>&quot;. In
<i><a href="http://www.ias.ac.in/sadhana/">Sadhana</a> (Proceedings of the Indian Academy of Sciences)</i>, Vol. 19, Dec.
1994, pp. 851-889.

</ul>
<!--<hr>
See an <a href="old.html">old version</a> of my home page for more links
and contact information.-->
</body>
</html>

