<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>


<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Balaraman Ravindran</title>
<meta name="keywords" content="">
<meta name="description" content="">
<link href="default.css" rel="stylesheet" type="text/css">
</head><body>
<div id="header">
<center>
	<div id="logo">
		<!--<h1>Balaraman Ravindran</h1>-->
	<img src="mug3.gif" height=150 align="middle" vspace=25>
	</div>
</center>
	<div id="address">
<font size=+2>Balaraman Ravindran</font><br>
BSB 349<br>
Computer Science and Engineering<br>
Indian Institute of Technology Madras<br>
Chennai, 600 036.<br>
Ph: +91-44-22574370<br>
ravi@cse.iitm.ac.in<br>
<ul>
			<li><a href="ravi.html" accesskey="1" title="">Home</a></li>
			<li><a href="publications.html" accesskey="2" title="">Publications</a></li>
			<li><a href="research.html" accesskey="3" title="">Research</a></li>
			<li><a href="teaching.html" accesskey="4" title="">Teaching</a></li>
			<li><a href="students.html" accesskey="5" title="">Students</a></li>
		</ul>
	</div>
</div>
<div id="content">
	<div id="colOne">
		<div class="content">
<p> My current research interests span the broader area of
machine learning, ranging from Spatio-temporal Abstractions in
Reinforcement Learning to social network analysis and Data/Text
Mining. Much of the work in my group is directed toward understanding 
interactions and learning from them. </p>

<a name="rl"></a><h4>Reinforcement Learning</h4>
<p>One of the main focus of research in our group is on building situated
learning agents that can incrementally solve larger and larger problems using
structures built from prior experience. We look at this both from a spatial and
temporal perspective, with motivations drawn from cognitive theories of
representation.</p>

<p>From a spatial, or a representation, perspective we want agents to be able to
incorporate only those aspects of their enivornment that are crucial for the
task at hand. We build on the notion of MDP homomorphisms proposed in my <a
href="paper_abstracts.html#2004RB">thesis</a> and have explored various
extensions to this basic framework [<a href="paper_abstracts.html#2004RBB">RB
2004</a>, <a href="paper_abstracts.html#2007RBM">RBM 2007</a>, <a
href="paper_abstracts.html#2007NR">NR 2007</a>, <a
href="paper_abstracts.html#2008NR">NR 2008</a>]. </p>

<p>These architectures work with an already abstract representation of the world.
Closer to the sensory level we are looking at the learning of visual routines
that can tell an agent what aspects of its visual input to focus on. These
visual routines then act as the feature extraction units that the higher levels
in the architecture choose from. This work is part of a joint project with
Profs.  Jeremy Wyatt and Richard Dearden from University of Birmingham and Dr.
Anurag Mittal and myself, from this Department, funded by the British Council
under the UKIERI program.</p>

<p>From a temporal perspective we have addressed issues of representations and
sub-tasks - the question of what is an adequate representation for the sub-task
at hand [<a href="paper_abstracts.html#2003RB2">RB 2003b</a>, <a
href="paper_abstracts.html#2003RB3">RB 2003c</a>, <a
href="paper_abstracts.html#2007RBM">RBM 2007</a>]. We are currently working on
using cognitively motivated representation schemes for hierarchical task
architectures. On the question of building temporal hierarchical architectures,
we are exploring issues regarding incremental learning of the hierarchy,
combining learning and planning; and looking at more cognitively motivated
representations of tasks and sub-tasks.</p>

<p>We are also exploring the realizations of these algorithms on real-robot
platforms. This requires us to address issues that are closer to the sensory
and motor control level, including visual cognition, and other localization
mechanisms [<a href="paper_abstracts.html#2009BRK">BRK 2009</a>]. We are also
looking at transfer of learning from one robot to another under several
constrained settings as well as the problem of learning from instructions.</p>

<a name="tm"></a><h4>Text Mining</h4>
<p>Our group has been looking at the marriage of both semantic and statistical
approaches to text mining tasks. Much of the work in the group has been driven
by specific problems. We have worked on the problem of text summarization [<a
href="paper_abstracts.html#2006SRR1">SRR2006a</a>, <a
href="paper_abstracts.html#2008AR2">2008ARb</a>, <a
href="paper_abstracts.html#2008AR1">2008ARa</a>] categorization [<a
href="paper_abstracts.html#2008SRR">SRR2008</a>, <a
href="paper_abstracts.html#2006SRR2">SRR2006b</a>], clustering [<a
href="paper_abstracts.html#2008JDR">JDR2008</a>, <a
href="paper_abstracts.html#2007JDRS">JDRS2007</a>], etc. Some of the current
projects are focused on (auto | financial | micro) blog analysis (part of the
work is funded by General Motors, India Science Labs), resume processing
(funded by Burning Glass Technologies), representative document set mining,
question answering systems, etc. </p>

<a name="dm"></a><h4>Data Mining</h4>
<p>My interest in data mining has been motivated partly by my desire to
understand the use of statistical models in mining, partly by my drive for doing
something of immediate relevance, and partly by the connections between my work
on abstraction and some of the problems in mining. One of the ongoing projects
is on opthalmic data mining with Sankara Nethralaya<a
href="http://www.sankaranethralaya.org/">^</a> [<a
href="paper_abstracts.html#2008RKRLV">RKR2008</a>, <a
href="paper_abstracts.html#2008CR">CR2008</a>]. We work closely with doctors
from their Vision Research Foundation on building better screening tools,
disease incidence prediction, risk factor analysis, etc.</p>

<p>We are also looking at telecom data analysis, funded by Ericsson R &amp; D,
India. The problems we focus on is trying to understand customer behavior
better through various analytics tools, including social network analysis [<a
href="paper_abstracts.html#2009KR">KR2009</a>, AR2010].</p>

<p><br></p>

<a name="misc"></a><h4>Awards and Service</h4>
<ul>
<li> Won a UKIERI funded project in 2009, jointly with Jeremey Wyatt, Richard
Deaden from University of Birmingham and Anurag Mittal, IIT Madras</li>
<li> Yahoo! Faculty Research and Engagement Gift, 2009</li>
<li> Rachit Arora, best student paper award, AND 2008</li>
</ul>
<p></p>
<ul>
<li> Program Co-Chair: PAKDD 2010.
<li> Local Arrangmenets Chair: HOIT 2007.
<li> Machine Learning Track Chair: ICISIP 2005.
<li> Program Committee Member: ICML 2008, AAAI 2010, AAMAS 2008, DASFAA 2007, 2008, AND 2008, 2009, 2010, IEEE CASE 2009, 2010, ICAI 2010. 
<li> Reviewer: 
<dl>
<dd>IEEE Transactions on Systems, Man and Cybernetics A and C
<dd>IEEE Transactions on Circuits and Systems 
<dd>IEEE Transactions on Multimedia
<dd>Journal of Machine Learning Research
<dd>Journal of Algorithms (Elsivier)
<dd>Information Processing and Management (Springer) 
<dd>Robotics and Autonomous Systems (Springer) 
<dd>Proceedings of the Indian Academy of Sciences
<dd>ICML 2002, 2003, and several other conferences
</dl>
</ul>

</div> </div> <div id="colTwo"> 
 <div class="content">
	
		<p> </p><ul> 
<li><font size="2"> <a href="#rl">Reinforcement Learning</a></li>
<li><font size="2"> <a href="#tm">Text Mining</a></li>
<li><font size="2"> <a href="#dm">Data Mining</a></li>
<p></p>
<li><font size="2"> <a href="#misc">Miscellaneous</a></li>
				</ul></div>
			<div class="content"><form method="get"
action="http://www.google.com/search"> <input name="q" size="17"
maxlength="255" value="" type="text"> <input name="btnG" value="Google Search"
type="submit"> </form></div>
<font size="1">	</font></div>
</div>
<div id="footer" style="clear: both;">
<font size="1">	</font><p><font size="1">Copyright 2009 Balaraman Ravindran. Designed based on a template by  <a href="http://freecsstemplates.org/"><strong>Free CSS Templates</strong></a> and <a href="http://people.csail.mit.edu/kersting/index.html">Kristian Kersting</a></font></p>
</div>
</body></html>
